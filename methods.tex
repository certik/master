
\section{DFT}

\subsection{Introduction}

Good books about DFT are \cite{DFT} and \cite{martin}, but they both contain much more topics which we don't need and some topics are missing in each of them, so this chapter gives a self-contained explanation of all one has to know about a many body quantum mechanics and the DFT in order to be able to do DFT calculations.

\subsection{Many Body Schrödinger Equation}

We use the Born-Oppenheimer approximation, which says that the nuclei of the treated atoms are seen as fixed. A stationary electronic state (for $N$ electrons) is then described by a wave function $\Psi({\bf r_1},{\bf r_2},\cdots,{\bf r}_N)$ fulfilling the many-body Schrödinger equation 
\begin{equation*}
  \hat H\ket\Psi=(\hat T+\hat U+\hat V)\ket\Psi=E\ket\Psi
\end{equation*}
where 
\begin{equation*}
  \hat T = \sum_i^N -{1\over2}\nabla_i^2
\end{equation*}
is the kinetic term, 
\begin{equation*}
  \hat U = \sum_{i<j}U({\bf r_i},{\bf r_j})= {1\over2}\sum_{i,j}U({\bf r_i},{\bf r_j})
\end{equation*}
\begin{equation*}
  U({\bf r_i},{\bf r_j})=U({\bf r_j},{\bf r_i})={1\over|{\bf r_i}-{\bf r_j}|}
\end{equation*}
is the electron-electron interaction term and 
\begin{equation*}
  \hat V = \sum_i^N v({\bf r_i})
\end{equation*}
\begin{equation*}
  v({\bf r_i})=\sum_k -{Z_k\over|{\bf r_i}-{\bf R_k}|}
\end{equation*}
is the interaction term between electrons and nuclei, where $R_k$ are positions of nuclei and $Z_k$ the number of nucleons in each nucleus (we are using atomic units). So for one atomic calculation with the atom nucleus in the origin, we have just $v({\bf r_i})=-{Z\over|{\bf r_i}|}$.

$|\Psi|^2=\Psi^*\Psi$ gives the probability density of measuring the first electron at the position $\bf r_1$, the second at $\bf r_2$, \dots and the Nth electron at the position ${\bf r}_N$. The normalization is such that $\int |\Phi|^2\d^3 r_1\d^3 r_2\dots\d^3 r_N=1$. The $\Psi$ is antisymmetric, i.e. $\Psi({\bf r_1},{\bf r_2},\cdots,{\bf r}_N)= -\Psi({\bf r_2},{\bf r_1},\cdots,{\bf r}_N)= -\Psi({\bf r_1},{\bf r}_N,\cdots,{\bf r_2})$ etc.

Integrating $|\Psi|^2$ over the first $N-1$ electrons is the probability density that the $N$th electron is at the position ${\bf r}_N$. Thus the probability density $n({\bf r})$ that any of the N electrons (i.e the first, or the second, or the third, \dots, or the $N$th) is at the position $\bf r$ is called the particle (or charge or electron) density and is therefore given by: 
\begin{equation*}
  n({\bf r})= \int \Psi^*({\bf r},{\bf r}_2,\cdots,{\bf r}_N) \Psi ({\bf r},{\bf r}_2,\cdots,{\bf r}_N) \,\d^3 r_2\,\d^3 r_3\cdots\d^3 r_N+
\end{equation*}
\begin{equation*}
  +\int \Psi^*({\bf r}_1,{\bf r},\cdots,{\bf r}_N) \Psi ({\bf r}_1,{\bf r},\cdots,{\bf r}_N) \,\d^3 r_1\,\d^3 r_3\cdots\d^3 r_N+\cdots
\end{equation*}
\begin{equation*}
  +\int \Psi^*({\bf r}_1,{\bf r}_2,\cdots,{\bf r}) \Psi ({\bf r}_1,{\bf r}_2,\cdots,{\bf r}) \,\d^3 r_1\,\d^3 r_2\,\d^3 r_3\cdots\d^3 r_{N-1}=
\end{equation*}
\begin{equation*}
  =\int(\delta({\bf r}-{\bf r}_1)+\delta({\bf r}-{\bf r}_2)+\cdots+\delta({\bf r}-{\bf r}_N))
\end{equation*}
\begin{equation*}
  \Psi^*({\bf r}_1,{\bf r}_2,\cdots,{\bf r}_N) \Psi ({\bf r}_1,{\bf r}_2,\cdots,{\bf r}_N) \,\d^3 r_1\,\d^3 r_2\,\d^3 r_3\cdots\d^3 r_{N}=
\end{equation*}
\begin{equation*}
  =\sum_{i=1}^N\int \braket{\Psi|{\bf r}_1,{\bf r}_2,\cdots,{\bf r}_N}\delta({\bf r}-{\bf r}_i) \braket{{\bf r}_1,{\bf r}_2,\cdots,{\bf r}_N|\Psi} \,\d^3 r_1\,\d^3 r_2\,\d^3 r_3\cdots\d^3 r_{N}=
\end{equation*}
\begin{equation*}
  =N\int \braket{\Psi|{\bf r}_1,{\bf r}_2,\cdots,{\bf r}_N}\delta({\bf r}-{\bf r}_1) \braket{{\bf r}_1,{\bf r}_2,\cdots,{\bf r}_N|\Psi} \,\d^3 r_1\,\d^3 r_2\,\d^3 r_3\cdots\d^3 r_{N}=
\end{equation*}
\begin{equation}
  =N\int \Psi^*({\bf r},{\bf r}_2,\cdots,{\bf r}_N) \Psi ({\bf r},{\bf r}_2,\cdots,{\bf r}_N) \,\d^3 r_2\,\d^3 r_3\cdots\d^3 r_N  \label{chargedensity}
\end{equation}
Thus $\int_\Omega n({\bf r})\,\d^3r$ gives the number of particles (and also the amount of charge) in the region of integration $\Omega$. Obviously $\int n({\bf r})\,\d^3r=N$.

The energy of the system is given by 
\begin{equation}
  E=\braket{\Psi|\hat H|\Psi}= \braket{\Psi|\hat T|\Psi}+\braket{\Psi|\hat U|\Psi}+\braket{\Psi|\hat V|\Psi}= T+U+V  \label{Emanybody}
\end{equation}
where 
\begin{equation*}
  T=\braket{\Psi|\hat T|\Psi}=\sum_i^N\int \Psi^*({\bf r_1},{\bf r_2},\cdots,{\bf r_N})(-\half\nabla_i^2) \Psi({\bf r_1},{\bf r_2},\cdots,{\bf r_N})\,\d^3 r_1\,\d^3 r_2\cdots\d^3 r_N
\end{equation*}
\begin{equation*}
  U=\braket{\Psi|\hat U|\Psi}
\end{equation*}
\begin{equation*}
  V=\braket{\Psi|\hat V|\Psi}=\sum_i^N\int \Psi^*({\bf r_1},{\bf r_2},\cdots,{\bf r_N})v({\bf r_i}) \Psi({\bf r_1},{\bf r_2},\cdots,{\bf r_N})\,\d^3 r_1\,\d^3 r_2\cdots\d^3 r_N=
\end{equation*}
\begin{equation*}
  =\sum_i^N\int \Psi^*({\bf r_1},{\bf r_2},\cdots,{\bf r_N})v({\bf r_1}) \Psi({\bf r_1},{\bf r_2},\cdots,{\bf r_N})\,\d^3 r_1\,\d^3 r_2\cdots\d^3 r_N=
\end{equation*}
\begin{equation*}
  =N\int \Psi^*({\bf r_1},{\bf r_2},\cdots,{\bf r_N})v({\bf r_1}) \Psi({\bf r_1},{\bf r_2},\cdots,{\bf r_N})\,\d^3 r_1\,\d^3 r_2\cdots\d^3 r_N=
\end{equation*}
\begin{equation}
  =\int v({\bf r}) n({\bf r})\d^3 r=V[n]  \label{V[n]}
\end{equation}
It needs to be stressed, that $E$ generally is \textbf{not} a functional of $n$ alone, only the $V[n]$ is. In the next section we show however, that if the $\ket{\Psi}$ is a ground state (of any system), then $E$ becomes a functional of $n$.

\subsection{The Hohenberg-Kohn Theorem}

The SE gives the map 
\begin{equation*}
  C: V \to \Psi
\end{equation*}
where $\Psi$ is the ground state. C is bijective (one-to-one correspondence), because to every $V$ we can compute the corresponding $\Psi$ from SE and two different $V$ and $V'$ (differing by more than a constant) give two different $\Psi$, because if $V$ and $V'$ gave the same $\Psi$, then by substracting 
\begin{equation*}
  \hat H\ket{\Psi}=E_{gs}\ket{\Psi}
\end{equation*}
from 
\begin{equation*}
  \hat H'\ket{\Psi}=(\hat H-\hat V+\hat V')\ket{\Psi}=E_{gs}'\ket{\Psi}
\end{equation*}
we would get $V-V'=E-E'$, which is a contradiction with the assumption that $V$ and $V'$ differ by more than a constant.

Similarly, from the ground state wavefunction $\Psi$ we can compute the charge density $n$ giving rise to the map 
\begin{equation*}
  D: \Psi \to n
\end{equation*}
which is also bijective, because to every $\Psi$ we can compute $n$ from (\ref{chargedensity}) and two different $\Psi$ and $\Psi'$ give two different $n$ and $n'$, because different $\Psi$ and $\Psi'$ give 
\begin{equation*}
  E_{gs}=\braket{\Psi|\hat H|\Psi}<\braket{\Psi'|\hat H|\Psi'}= \braket{\Psi'|\hat H'+\hat V-\hat V'|\Psi'}=E_{gs}'+\int n'({\bf r}) (v({\bf r})-v'({\bf r}))\,\d^3 r
\end{equation*}
\begin{equation*}
  E_{gs}'=\braket{\Psi'|\hat H'|\Psi'}<\braket{\Psi|\hat H'|\Psi}= \braket{\Psi|\hat H+\hat V'-\hat V|\Psi}=E_{gs}+\int n({\bf r}) (v'({\bf r})-v({\bf r}))\,\d^3 r
\end{equation*}
adding these two inequalities together gives 
\begin{equation*}
  0<\int n'({\bf r}) (v({\bf r})-v'({\bf r}))\,\d^3 r + \int n({\bf r}) (v'({\bf r})-v({\bf r}))\,\d^3 r= \int (n({\bf r})-n'({\bf r}))(v'({\bf r})-v({\bf r}))\,\d^3 r
\end{equation*}
which for $n=n'$ gives $0<0$, which is nonsense, so $n\neq n'$.

So we have proved that for a given ground state density $n_0({\bf r})$ (generated by a potential $\hat V_0$) it is possible to calculate the corresponding ground state wavefunction $\Psi_0({\bf r_1},{\bf r_2},\cdots,{\bf r_N})$, in other words, $\Psi_0$ is a unique functional of $n_0$: 
\begin{equation*}
  \Psi_0=\Psi_0[n_0]
\end{equation*}
so the ground state energy $E_0$ is also a functional of $n_0$
\begin{equation*}
  E_0=\braket{\Psi_0[n_0]|\hat T+\hat U+\hat V_0|\Psi_0[n_0]}=E[n_0]
\end{equation*}
We define an energy functional 
\begin{equation}
  E_{v_0}[n]=\braket{\Psi[n]|\hat T+\hat U+\hat V_0|\Psi[n]}= \braket{\Psi[n]|\hat T+\hat U|\Psi[n]}+\int v_0({\bf r})n({\bf r})\d^3r  \label{Efunct}
\end{equation}
where $\ket{\Psi[n]}$ is any ground state wavefunction (generated by an arbitrary potential), that is, $n$ is a ground state density belonging to an arbitrary system. $E_0$ which is generated by the potential $V_0$ can then be expressed as 
\begin{equation*}
  E_0=E_{v_0}[n_0]
\end{equation*}
and for $n\neq n_0$ we have (from the Ritz principle) 
\begin{equation*}
  E_0<E_{v_0}[n]
\end{equation*}
and one has to minimise the functional $E_{v_0}[n]$: 
\begin{equation}
  E_0=\min_n E_{v_0}[n]  \label{Emin}
\end{equation}
The term 
\begin{equation*}
  \braket{\Psi[n]|\hat T+\hat U|\Psi[n]}\equiv F[n]
\end{equation*}
in (\ref{Efunct}) is universal in the sense that it doesn't depend on $\hat V_0$. It can be proven \cite{DFT}, that $F[n]$ is a functional of $n$ for degenerated ground states too, so (\ref{Emin}) stays true as well.

The ground state densities in (\ref{Efunct}) and (\ref{Emin}) are called \textbf{pure-state v-representable} because they are the densities of (possible degenerate) ground state of the Hamiltonian with some local potential $v({\bf r})$. One may ask a question if all possible functions are v-representable (this is called the v-representability problem). The question is relevant, because we need to know which functions to take into account in the minimisation proccess (\ref{Emin}). Even though not every function is v-representable \cite{DFT}, every density defined on a grid (finite of infinite) which is strictly positive, normalized and consistent with the Pauli principle is ensemble v-representable. Ensemble v-representation is just a simple generalization of the above, for details see \cite{DFT}. In plain words, we are fine.

The functional $E_{v_0}[n]$ in (\ref{Emin}) depends on the particle number $N$, so in order to get $n$, we need to solve the variational formulation 
\begin{equation*}
  {\delta\over\delta n}\left(E_v[n]-\mu(N)\int n(\bf r)\d^3r\right)=0
\end{equation*}
so 
\begin{equation}
  {\delta E_v[n]\over\delta n}=\mu(N)  \label{euler}
\end{equation}
Let the $n_N(\bf r)$ be the solution of (\ref{euler}) with a particle number $N$ and the energy $E_N$: 
\begin{equation*}
  E_N=E_v[n_N]
\end{equation*}
The Lagrangian multiplier $\mu$ is the exact chemical potential of the system 
\begin{equation*}
  \mu(N)={\partial E_N\over\partial N}
\end{equation*}
becuase 
\begin{equation*}
  E_{N+\epsilon}-E_N=E_v[n_{N+\epsilon}]-E_v[n_N] =\int {\delta E_v\over\delta n} (n_{N+\epsilon}-n_N)\d^3r=
\end{equation*}
\begin{equation*}
  =\int \mu(N) (n_{N+\epsilon}-n_N)\d^3r =\mu(N)(N+\epsilon-N)=\mu(N)\epsilon
\end{equation*}
so 
\begin{equation*}
  \mu(N)={E_{N+\epsilon}-E_N\over\epsilon} \ \longrightarrow \ {\partial E_N\over\partial N}
\end{equation*}

\subsection{The Kohn-Sham Equations}

Consider an auxiliary system of $N$ noninteracting electrons (noninteracting gas): 
\begin{equation*}
  \hat H_s=\hat T+\hat V_s
\end{equation*}
Then the many-body ground state wavefunction can be decomposed into single particle orbitals 
\begin{equation*}
  \ket{\Psi ({\bf r_1},{\bf r_2},\cdots,{\bf r_N})}= \ket{\psi_1({\bf r})}\ket{\psi_2({\bf r})}\cdots\ket{\psi_N({\bf r})}
\end{equation*}
and 
\begin{equation*}
  E_s[n]=T_s[\{\psi_i[n]\}]+V_s[n]
\end{equation*}
where 
\begin{equation*}
  T_s[n]=\braket{\Psi[n]|\hat T|\Psi[n]}= \sum_i\braket{\psi_i|-\half\nabla^2|\psi_i}
\end{equation*}
\begin{equation*}
  V_s[n]=\braket{\Psi[n]|\hat V|\Psi[n]}=\int v_s({\bf r})n({\bf r})\d^3r
\end{equation*}
From (\ref{euler}) we get 
\begin{equation}
  \mu={\delta E_s[n]\over\delta n({\bf r})}= {\delta T_s[n]\over\delta n({\bf r})}+{\delta V_s[n]\over\delta n({\bf r})}= {\delta T_s[n]\over\delta n({\bf r})}+v_s({\bf r})  \label{noninteract}
\end{equation}
Solution to this equation gives the density $n_s$.

Now we want to express the energy in (\ref{Emanybody}) using $T_s$ and $E_H$ for convenience, where $E_H$ is the classical electrostatic interaction energy of the charge distribution $n({\bf r})$: 
\begin{equation*}
  \nabla^2 V_H=n({\bf r})
\end{equation*}
or uquivalently 
\begin{equation*}
  E_H[n]=\half\int\int {n({\bf r})n({\bf r'})\over|{\bf r}-{\bf r'}|} \d^3r\d^3r'
\end{equation*}
\begin{equation}
  V_H({\bf r})={\delta E_H\over\delta n({\bf r})}=\half\int {n({\bf r'})\over|{\bf r}-{\bf r'}|} \d^3r'  \label{V_H}
\end{equation}
So from (\ref{Efunct}) we get 
\begin{equation*}
  E[n]=(T+U)[n]+V[n]=T_s[n]+E_H[n]+(T-T_s+U-E_H)[n]+V[n]=
\end{equation*}
\begin{equation}
  =T_s[n]+E_H[n]+E_{xc}[n]+V[n]  \label{Efunctxc}
\end{equation}
The rest of the energy is denoted by $E_{xc}=U-E_H+T-T_s$ and it is called is the exchange and correlation energy functional. From (\ref{euler})
\begin{equation*}
  \mu={\delta E[n]\over\delta n({\bf r})}= {\delta T_s[n]\over\delta n({\bf r})}+ {\delta E_H[n]\over\delta n({\bf r})}+ {\delta E_{xc}[n]\over\delta n({\bf r})}+ {\delta V[n]\over\delta n({\bf r})}
\end{equation*}
From (\ref{V_H}) we have 
\begin{equation*}
  {\delta E_H\over\delta n({\bf r})}=V_H({\bf r})
\end{equation*}
from (\ref{V[n]}) we get 
\begin{equation*}
  {\delta V[n]\over\delta n({\bf r})}=v({\bf r})
\end{equation*}
we define 
\begin{equation}
  {\delta E_{xc}[n]\over\delta n({\bf r})}=V_{xc}({\bf r})  \label{Vxcpot}
\end{equation}
so we arrive at 
\begin{equation}
  \mu={\delta E[n]\over\delta n({\bf r})}= {\delta T_s[n]\over\delta n({\bf r})}+V_H({\bf r})+V_{xc}({\bf r})+v({\bf r})  \label{interact}
\end{equation}
Solution to this equation gives the density $n$. Comparing (\ref{interact}) to (\ref{noninteract}) we see that if we choose 
\begin{equation*}
  v_s\equiv V_H+V_{xc}+v
\end{equation*}
then $n_s({\bf r})\equiv n({\bf r})$. So we solve the Kohn-Sham equations of this auxiliary non-interacting system 
\begin{equation}
  (-\half\nabla^2+v_s({\bf r}))\psi_i({\bf r}) \equiv(-\half\nabla^2+V_H({\bf r})+V_{xc}({\bf r})+v({\bf r}))\psi_i({\bf r}) =\epsilon_i\psi({\bf r})  \label{KSeq}
\end{equation}
which yield the orbitals $\psi_i$ that reproduce the density $n({\bf r})$ of the original interacting system 
\begin{equation}
  n({\bf r})\equiv n_s({\bf r})=\sum_i^N|\psi_i({\bf r})|^2  \label{KSdensity}
\end{equation}
The sum is taken over the lowest $N$ energies. Some of the $\psi_i$ can be degenerated, but it doesn't matter - the index $i$ counts every eigenfunction including all the degenerated. In plain words, the trick is in realising, that the ground state energy can be found by minimising the energy functional (\ref{Efunct}) and in rewriting this functional into the form (\ref{Efunctxc}), which shows that the interacting system can be treated as a noninteracting one with a special potential.

\subsection{The XC Term}

The exchange and correlation functional 
\begin{equation*}
  E_{xc}[n]=(T+U)[n]-E_H[n]-T_S[n]
\end{equation*}
can always be written in the form 
\begin{equation*}
  E_{xc}[n]=\int n({\bf r}')\epsilon_{xc}({\bf r}';n)\d^3r'
\end{equation*}
where the $\epsilon_{xc}({\bf r}';n)$ is called the xc energy density.

Unfortunately, no one knows $\epsilon_{xc}({\bf r}';n)$ exactly (yet). The most simple approximation is the \textbf{local density approximation} (LDA), for which the xc energy density $\epsilon_{xc}$ at $\bf r$ is taken as that of a homogeneous electron gas (the nuclei are replaced by a uniform positively charged background, density $n=\rm const$) with the same local density: 
\begin{equation*}
  \epsilon_{xc}({\bf r};n)\approx\epsilon_{xc}^{LD}(n({\bf r}))
\end{equation*}

The xc potential $V_{xc}$ defined by (\ref{Vxcpot}) is then 
\begin{equation*}
  V_{xc}({\bf r};n)={\delta E_{xc}[n]\over\delta n({\bf r})}= \epsilon_{xc}({\bf r}';n)+ \int n({\bf r}'){\delta \epsilon_{xc}({\bf r}';n)\over\delta n({\bf r})}\d^3r'
\end{equation*}
which in the LDA becomes 
\begin{equation}
  V_{xc}({\bf r};n) =\epsilon_{xc}^{LD}(n)+n{\d \epsilon_{xc}^{LD}(n)\over \d n}= {\d \over \d n}\left(n\epsilon_{xc}^{LD}(n)\right)= V_{xc}^{LD}(n)  \label{Vxcld}
\end{equation}
The xc energy density $\epsilon_{xc}^{LD}$ of the homogeneous gas can be computed exactly\cite{martin}: 
\begin{equation*}
  \epsilon_{xc}^{LD}(n)=\epsilon_x^{LD}(n)+\epsilon_c^{LD}(n)
\end{equation*}
where the $\epsilon_x^{LD}$ is the electron gas exchange term given by\cite{martin} 
\begin{equation*}
  \epsilon_x^{LD}(n)=-{3\over4\pi}(3\pi^2 n)^{1\over3}
\end{equation*}
the rest of $\epsilon_{xc}^{LD}$ is hidden in $\epsilon_c^{LD}(n)$ for which there doesn't exist an analytic formula, but the correlation energies are known exactly from quantum Monte Carlo (QMC) calculations by Ceperley and Alder\cite{pickett}. The energies were fitted by Vosko, Wilkes and Nussair (VWN) with $\epsilon_c^{LD}(n)$ and they got accurate results with errors less than $0.05\rm\,mRy$ in $\epsilon_c^{LD}$, which means that $\epsilon_c^{LD}(n)$ is virtually known exactly. VWN result: 
\begin{equation*}
  \epsilon_c^{LD}(n)\approx {A\over2}\left\{ \ln\left(y^2\over Y(y)\right)+{2b\over Q}\arctan\left(Q\over 2y+b\right)+ \right.
\end{equation*}
\begin{equation*}
  \left. -{by_0\over Y(y_0)}\left[\ln\left((y-y_0)^2\over Y(y)\right) +{2(b+2y_0)\over Q}\arctan\left(Q\over 2y+b\right) \right] \right\}
\end{equation*}
where $y=\sqrt{r_s}$, $Y(y)=y^2+by+c$, $Q=\sqrt{4c-b^2}$, $y_0=-0.10498$, $b=3.72744$, $c=12.93532$, $A=0.0621814$ and $r_s$ is the electron gas parameter, which gives the mean distance between electrons (in atomic units): 
\begin{equation*}
  r_s=\left(3\over4\pi n\right)^{1\over3}
\end{equation*}

The xc potential is then computed from (\ref{Vxcld}): 
\begin{equation*}
  V_{xc}^{LD}=V_x^{LD}+V_c^{LD}
\end{equation*}
\begin{equation*}
  V_x^{LD}=-{1\over\pi}(3\pi^2 n)^{1\over3}
\end{equation*}


\begin{equation*}
  V_c^{LD}={A\over2}\left\{ \ln\left(y^2\over Y(y)\right)+{2b\over Q}\arctan\left(Q\over 2y+b\right)+ \right.
\end{equation*}
\begin{equation*}
  \left. -{by_0\over Y(y_0)}\left[\ln\left((y-y_0)^2\over Y(y)\right) +{2(b+2y_0)\over Q}\arctan\left(Q\over 2y+b\right) \right] \right\}+
\end{equation*}
\begin{equation*}
  -{A\over6}{c(y-y_0)-by_0y\over (y-y_0)Y(y)}
\end{equation*}

Some people also use Perdew and Zunger formulas, but they give essentially the same results. The LDA, although very simple, is suprisingly successful. More sophisticated approximations exist, for example the generalized gradient approximation (GGA), which sometimes gives better results than the LDA, but is not perfect either. Other options include orbital-dependent (implicit) density functionals or a linear response type functionals, but this topic is still evolving. The conclusion is, that the LDA is a good approximation to start with, and only when we are not satisfied, we will have to try some more accurate and modern approximation.

RLDA: Relativistic corrections to the energy-density functional were proposed by MacDonald and Vosko and basically are just a change in $\epsilon_x^{LD}(n)\rightarrow\epsilon_x^{LD}(n)R$: 
\begin{equation*}
  R = \left[1-{3\over2}\left(\beta\mu-\ln(\beta+\mu)\over\beta^2\right)^2\right]
\end{equation*}
where 
\begin{equation*}
  \mu=\sqrt{1+\beta^2}
\end{equation*}
and 
\begin{equation*}
  \beta={(3\pi^2n)^{1\over3}\over c}
\end{equation*}
We also need to calculate these derivatives: 
\begin{equation*}
  {\d R\over\d \beta}= -6{\beta\mu-\ln(\beta+\mu)\over\beta^2}\left({1\over\mu}- {\beta\mu-\ln(\beta+\mu)\over\beta^3}\right)
\end{equation*}
\begin{equation*}
  {\d \beta\over\d n}={\beta\over 3n}
\end{equation*}
\begin{equation*}
  {\d \epsilon_x^{LD}\over\d n}={\epsilon_x^{LD}\over 3n}
\end{equation*}
So 
\begin{equation*}
  V_x^{RLD}=\epsilon_x^{LD}R+n{\d \epsilon_x^{LD}R\over\d n}= {4\over3}\epsilon_x^{LD}R+{1\over3}\epsilon_x^{LD}{\d R\over\d\beta}\beta
\end{equation*}
For $c\to\infty$ we get $\beta\to0$, $R\to1$ and $V_x^{RLD}\to {4\over3}\epsilon_x^{LD}=V_x^{LD}$ as expected, because 
\begin{equation*}
  \lim_{\beta\to0}{\beta\sqrt{1+\beta^2}-\ln(\beta+\sqrt{1+\beta^2})\over \beta^2} = 0
\end{equation*}

\subsection{Iteration to Self-consistency}

The $V_H$ and $V_{xc}$ potentials in the Kohn-Sham equations (\ref{KSeq}) depend on the solution $n$ thus the KS equations need to be iterated to obtain a self-consistent density. One can regard the KS procedure as a nonlinear operator $\hat F$ which satisfies (at the $M$th iteration) 
\begin{equation*}
  n_M^{\rm out}=\hat F n_M
\end{equation*}
and the problem is to find the self-consistent density which satisfies 
\begin{equation*}
  n=\hat F n
\end{equation*}

Due to the long-range nature of the Coulomb interaction, a small change in the input density $n_M$ can lead to a relatively large change in the output density $\hat F n_M$, thus it is not possible to use the output density itself as the input density for the next iteration, since large unstable charge oscillations arise. Rather it is essential to mix input and output densities in an appropriate manner to obtain a new input density.

The $n(\bf r)$ is in practice defined on some grid, or using coefficients of plane waves, local orbitals or the like, which means that the precise relation 
\begin{equation*}
  \one=\int \ket{\bf r}\bra{\bf r}\d^3 r
\end{equation*}
is changed for 
\begin{equation*}
  \one\approx\sum_i \ket{{\bf r}_i}\bra{{\bf r}_i}
\end{equation*}
in the case of a grid (or some other basis like plane waves can be used instead of $\ket{{\bf r}_i}$) and $n({\bf r})=\braket{{\bf r}|n}$ is approximated by $n({\bf r}_i)=\braket{{\bf r}_i|n}$. Let 
\begin{equation*}
  \x=(x_1,x_2,x_3,...),\quad x_i\equiv n({\bf r}_i)=\braket{{\bf r}_i|n}
\end{equation*}
and 
\begin{equation*}
  \F(\x_M)\equiv \hat F n_M, \quad F_i= (\hat F n_M)({\bf r}_i)
\end{equation*}
the self-consistency is reached when $\F(\x)=\x$.

So the problem is in solving the equation 
\begin{equation*}
  \F(\x)=\x
\end{equation*}
where $\x$ denotes a vector in many dimensions (the number of points in the grid). It can also be expressed in the form of the residual $\R(\x)=\F(\x)-\x$ as 
\begin{equation*}
  \R(\x)=0
\end{equation*}
Almost all of the methods start with approximating 
\begin{equation}
  \R(\x_{M+1})-\R(\x_M)\approx\J\cdot(\x_{M+1}-\x_M)  \label{lin}
\end{equation}
where the Jacobian 
\begin{equation*}
  J_{ij}={\partial R_i\over\partial x_j}
\end{equation*}
We want $\R(\x_{M+1})=0$, so substituting that into (\ref{lin}) we get 
\begin{equation*}
  \x_{M+1}\approx\x_M+\J^{-1}\cdot(\R(\x_{M+1})-\R(\x_M))= \x_M-\J^{-1}\cdot\R(\x_M)
\end{equation*}
If we knew the Jacobian exactly, this would be the multidimensional Newton-Raphson method, but we can only make approximations to $\J$ using a sequence of $\J_0$, $\J_1$, $\J_2$, \dots: 
\begin{equation}
  \x_{M+1}=\x_M-\J_M^{-1}\cdot\R(\x_M)  \label{Jaciter}
\end{equation}
and the rate of convergence is determined by the quality of the Jacobian. These type of methods are called quasi-Newton-Raphson methods.

The simplest approach is to use the \textbf{linear mixing} scheme for which 
\begin{equation*}
  \J_M^{-1}=-\alpha\one
\end{equation*}
so 
\begin{equation*}
  \x_{M+1}=\x_M+\alpha\R(\x_M)=\x_M+\alpha(\F(\x_M)-\x_M)
\end{equation*}
where $0<\alpha\le1$ is the mixing parameter, working value is somewhere around $\alpha=0.1$ to $\alpha=0.3$. Unfortunately, this procedure is slow and also we do not explore all the possible densities with this mixing, which means that we don't get the correct density with any accuracy, because we get stuck at a "stiff" situation for which continued iteration does not improve the distance $|\R(\x_M)|$ between input and output densities. On the other hand it's very easy to implement and it works in most cases, although slowly.

Surprisingly very good method is this: 
\begin{equation*}
  \J_M^{-1}=-{\rm diag}(\beta_1,\beta_2,\beta_3,\dots)
\end{equation*}
start with $\beta_1=\beta_2=\beta_3=\cdots=\alpha$ and at every iteration adjust the parameters $\beta_i$ according to this very simple algorithm: if $R_i(\x_{M-1})R_i(\x_M)>0$ then increase $\beta_i$ by $\alpha$ (if $\beta_i>\alpha_{max}$, set $\beta_i=\alpha_{max}$) otherwise set $\beta_i=\alpha$. In my tests it behaves almost as well as the second Broyden method.

More sophisticated approach is the Broyden update, which updates the $\J$ successively at every iteration. The \textbf{first Broyden method} is using this formula: 
\begin{equation*}
  \J_{M+1}=\J_M-{(\Delta\R(\x_M)+\J_M\cdot\Delta\x_M)\Delta\x_M^T\over |\Delta\x_M|^2}
\end{equation*}
which has the disadvantage that we need to compute the inverse Jacobian in (\ref{Jaciter}) at every iteration, which is impossible in our case. The \textbf{second Broyden method} updates the inverse Jacobian directly using this formula 
\begin{equation}
  \J_{M+1}^{-1}=\J_M^{-1}+{(\Delta\x_M-\J_M^{-1}\cdot\Delta\R(\x_M)) \Delta\R(\x_M)^T\over |\Delta\R(\x_M)|^2}  \label{Bupdate}
\end{equation}
starting with the linear mixing: 
\begin{equation*}
  \J_0^{-1}=-\alpha\one
\end{equation*}
It is impossible to store the whole dense matrix of the inverse Jacobian, but fortunately it is not necessary, realising that the (\ref{Bupdate}) has a very simple structure \cite{srivastava}: 
\begin{equation*}
  \J_{M+1}^{-1}=\J_M^{-1}+{\bf u}{\bf v}^T
\end{equation*}
with 
\begin{equation}
  {\bf u}=\Delta\x_M-\J_M^{-1}\cdot\Delta\R(\x_M)  \label{vecu}
\end{equation}
\begin{equation*}
  {\bf v}={\Delta\R(\x_M)\over |\Delta\R(\x_M)|^2}
\end{equation*}
so the whole inverse Jacobian can be written as 
\begin{equation*}
  \J_M^{-1}=-\alpha\one+{\bf u}_1{\bf v}_1^T+{\bf u}_2{\bf v}_2^T+ {\bf u}_3{\bf v}_3^T+\cdots
\end{equation*}
and we only need to know how to apply such a Jacobian to an arbitrary vector, which is needed in (\ref{vecu}) and (\ref{Jaciter}): 
\begin{equation*}
  \J_M^{-1}\cdot\y=-\alpha\y+{\bf u}_1({\bf v}_1^T\y) +{\bf u}_2({\bf v}_2^T\y)+ {\bf u}_3({\bf v}_3^T\y)+\cdots
\end{equation*}
Thus instead of the whole dense matrix, we only need to save the vectors ${\bf u}$ and ${\bf v}$ from every iteration.

Vanderbilt and Louie \cite{vanderbiltlouie} suggested a \textbf{modified Broyden method}, which incorporates weights, but Eyert \cite{eyert} showed that if all the weights are used to tune the iteration process to its fastest convergence, they, in fact, cancel out and the result of the scheme is called by Eyert the \textbf{generalized Broyden method}, whose scheme shown by Eyert is exactly the same as for the \textbf{Anderson mixing}: 
\begin{equation*}
  \sum_{p=M-k}^{M-1}(1+\omega_0^2\delta_{pn})\Delta\R(\x_n)^T\Delta\R(\x_p) \gamma_p =\Delta\R(\x_n)^T\R(\x_M)
\end{equation*}
\begin{equation*}
  \x_{M+1}=\x_M+\beta_M\R(\x_M)-\sum_{p=M-k}^{M-1}\gamma_p (\Delta\x_p+\beta_M\Delta\R(\x_p))
\end{equation*}
which according to Eyert should converge even faster than the second Broyden method, but it doesn't in my own implementation. $\omega_0$ is added just for a numerical stability, good value is $\omega=0.01$, but it can also be switched off by $\omega_0=0$. $p$ is the number of last iterations to use, good value according to Eyert is $p=5$, $\beta_M$ shouldn't influence the convergence much for $p=5$.

The problem with $n$ is that there are two conditions which need to be satisfied 
\begin{equation*}
  n>0
\end{equation*}
and the normalization 
\begin{equation*}
  \int n({\bf r}) \d^3r=Z
\end{equation*}
The Newton method converges to the correct norm, but slowly. The condition $n>0$ however causes great instability. One option could be to use a logistic function like 
\begin{equation*}
  n(r)={C\over 1+e^{-x(r)}}
\end{equation*}
for sufficiently large $C$ and solve for $x$, which can be both positive and negative. But more elegant solution is to mix $V_h+V_{xc}$ instead of the densities.

\subsection{Example: Pb Atom}

To illustrate the explained theory, we will show how to calculate the Pb atom. We have $N=82$ and 
\begin{equation*}
  v({\bf r}_i)=-{82\over |{\bf r}_i|}
\end{equation*}
and we need to sum over the lowest 82 eigenvalues in (\ref{KSdensity}). One option (the correct one) is to automatically try different "n" and "l" until we are sure we got the lowest 82 energies. But for Pb the combination of "n" and "l" is well-known, it is (first number is $n$, the letter is $l$ and the number in superscript gives the number of times the particular eigenvalue needs to be taken into account in the sum): $1S^2$, $2S^2$, $2P^6$, $3S^2$, $3P^6$, $3D^{10}$, $4S^2$, $4P^6$, $4D^{10}$, $4F^{14}$, $5S^2$, $5P^6$, $5D^{10}$, $6S^2$, $6P^2$ (notice the 5F and 5G are missing). Together it is 82 eigenvalues. The KS energies for these eigenvalues are:

-2701.6 -466.18 -471.87 -111.45 -108.24 -92.183 -24.498 -22.086 -15.119 -5.6606 -3.9570 -2.9743 -.92718 -.33665 -.14914

\section{Pseudopotentials}

\subsection{Introduction}

Literature about pseudopotentials is unfortunately scattered among many arcticles, so this section gives a review and should save the reader from a lot of troubles.

\subsection{Hermitian Operators in Spherical Symmetry}

We show that every Hermitian operator $\hat V$ in the spherical symmetric problem ($\hat V=R^{-1}\hat VR$) can be written in the form 
\begin{equation}
  \hat V=\sum_{lm}\ket{lm}\hat V_l\bra{lm}  \label{lmexpansion}
\end{equation}
where the operator $\hat V_l=\braket{lm|\hat V|lm}$ has matrix elements 
\begin{equation*}
  \braket{\rho|\hat V_l|\rho'}=\bra{lm}\braket{\rho|\hat V|\rho'}\ket{lm}= V_l(\rho,\rho')
\end{equation*}
{\bf Proof:} Matrix elements of a general Hermitian operator $\hat V$ are 
\begin{equation*}
  \braket{{\bf r}|\hat V|\varphi}= \int\braket{{\bf r}|\hat V|{\bf r'}}\braket{{\bf r'}|\varphi}\d^3r'= \int V({\bf r},{\bf r'})\varphi({\bf r'})\d^3r'
\end{equation*}
where 
\begin{equation*}
  V({\bf r}, {\bf r'})=\braket{{\bf r}|\hat V|{\bf r'}}
\end{equation*}
In spherical symmetry, we have 
\begin{equation*}
  \braket{{\bf r}|\hat V|\varphi} =\braket{{\bf r}|R^{-1}\hat VR|\varphi} =\braket{{\bf r}|R^{\dagger}\hat VR|\varphi} =\int\braket{{\bf r}|R^{\dagger}\hat VR|{\bf r'}}\braket{{\bf r'}|\varphi}\d^3r' =
\end{equation*}
\begin{equation*}
  =\int\braket{R{\bf r}|\hat V|R{\bf r'}}\braket{{\bf r'}|\varphi}\d^3r' =\int V(R{\bf r},R{\bf r'})\varphi({\bf r'})\d^3r'
\end{equation*}
where $R$ is the rotation operator (it's unitary). We have thus derived $V(R{\bf r},R{\bf r'})=V({\bf r},{\bf r'})$ true for any $R$, which means that the the kernel only depends on $\rho$, $\rho'$ and ${\bf\hat r}\cdot{\bf\hat r'}$, where ${\bf r}=\rho{\bf\hat r}$ and ${\bf r'}=\rho'{\bf\hat r'}$. So we obtain using (\ref{fylm})
\begin{equation*}
  V({\bf r}, {\bf r'})=V(\rho,\rho',{\bf\hat r}\cdot{\bf\hat r'})= \sum_{lm} Y_{lm}({\bf\hat r}) V_l(\rho,\rho') Y_{lm}^*({\bf\hat r'})
\end{equation*}
where 
\begin{equation*}
  V_l(\rho,\rho')={(2l+1)^2\over8\pi}\int_{-1}^1 P_l(x)V_l(\rho,\rho',x)\d x
\end{equation*}
In Dirac notation: 
\begin{equation*}
  V({\bf r}, {\bf r'})=\braket{{\bf r}|\hat V|{\bf r'}} =\bra{\bf\hat r}\braket{\rho|\hat V|\rho'}\ket{\bf\hat r'} =\sum_{lml'm'}\braket{{\bf\hat r}|lm}\bra{lm}\braket{\rho|\hat V|\rho'} \ket{l'm'}\braket{l'm'|\bf\hat r'}
\end{equation*}
From the above derivation we see that we must have: 
\begin{equation*}
  \bra{lm}\braket{\rho|\hat V|\rho'}\ket{l'm'}= V_l(\rho,\rho')\delta_{ll'}\delta_{mm'}
\end{equation*}
in other words 
\begin{equation}
  V_l(\rho,\rho')=\bra{lm}\braket{\rho|\hat V|\rho'}\ket{lm}  \label{vlm2}
\end{equation}
so we get 
\begin{equation*}
  \braket{{\bf r}|\hat V|{\bf r'}} =\sum_{lm}\braket{{\bf\hat r}|lm}V_l(\rho,\rho')\braket{lm|\bf\hat r'} =\sum_{lm}Y_{lm}(\theta,\phi) V_l(\rho,\rho') Y_{lm}^*(\theta',\phi')
\end{equation*}
and 
\begin{equation*}
  \hat V =\sum_{lm}\ket{lm}\braket{lm|\hat V|lm}\bra{lm} =\sum_{lm}\ket{lm}\hat V_l\bra{lm}
\end{equation*}
where the operator $\hat V_l=\braket{lm|\hat V|lm}$ only acts on the radial part of the wavefunction and according to (\ref{vlm2}) it doesn't depend on $m$. Also according to (\ref{vlm2}) its matrix elements are 
\begin{equation*}
  \braket{\rho|\hat V_l|\rho'}=\bra{lm}\braket{\rho|\hat V|\rho'}\ket{lm}= V_l(\rho,\rho')
\end{equation*}

\subsection{Nonlocal Pseudopotentials}

A nonlocal pseudopotential $\hat V$ is just a general Hermitian operator. We
only want to construct pseudopotentials in the spherical problem, so every
pseudopotential can be written in the form (\ref{lmexpansion}). In practice we
only use either {\it local} (the operator $\hat V$ is local) or {\it semilocal}
(the operator $\hat V$ is radially local, but angularly nonlocal) pseudopotential.

Local potential (radially and angularly local) is defined by: 
\begin{equation*}
  \braket{{\bf r}|\hat V|{\bf r'}}=V(\rho)\braket{{\bf r}|{\bf r'}}
\end{equation*}
so we can simply write 
\begin{equation}
  \hat V=V(\rho)  \label{loc1}
\end{equation}
so 
\begin{equation*}
  V_l(\rho,\rho') =\bra{lm}\braket{\rho|\hat V|\rho'}\ket{lm} =V(\rho)\braket{\rho|\rho'} =V(\rho){\delta(\rho-\rho')\over\rho^2}
\end{equation*}
so it turned out that the kernel is local and doesn't depend on $l$ and we get 
\begin{equation*}
  V({\bf r}(\rho,\theta,\phi), {\bf r'}(\rho',\theta',\phi'))= \sum_{lm}Y_{lm}(\theta,\phi) V(\rho){\delta(\rho-\rho')\over\rho^2} Y_{lm}^*(\theta',\phi')=
\end{equation*}
\begin{equation*}
  =V(\rho){1\over\rho^2\sin\theta} \delta(\rho-\rho')\delta(\theta-\theta')\delta(\phi-\phi')= V(\rho)\delta({\bf r}-{\bf r}')
\end{equation*}
and 
\begin{equation*}
  \braket{{\bf r}|\hat V|\varphi}=\int V(\rho)\delta({\bf r}-{\bf r}') \varphi({\bf r'})\d^3r'=V(\rho)\varphi({\bf r})
\end{equation*}
so we recover (\ref{loc1}). But we are just fooling around, there's nothing new in these formulas.

For a semilocal potential (radially local, but angularly nonlocal), the kernel cannot depend on $m$ and is radially local, so: 
\begin{equation*}
  \braket{\rho|\hat V_l|\rho'}=V_l(\rho,\rho') =\bra{lm}\braket{\rho|\hat V|\rho'}\ket{lm} =V_l(\rho)\braket{\rho|\rho'} =V_l(\rho){\delta(\rho-\rho')\over\rho^2}
\end{equation*}
so the kernel is local and does depend on $l$ and we simply write 
\begin{equation*}
  \hat V_l=V_l(\rho)
\end{equation*}
and 
\begin{equation}
  \hat V=\sum_{lm} \ket{lm}V_l(\rho)\bra{lm}  \label{semi}
\end{equation}
We can also calculate the same result explicitly in the $\bf r$ representation: 
\begin{equation*}
  V({\bf r}(\rho,\theta,\phi), {\bf r'}(\rho',\theta',\phi'))= \sum_{lm}Y_{lm}(\theta,\phi) V_l(\rho){\delta(\rho-\rho')\over\rho^2} Y_{lm}^*(\theta',\phi')
\end{equation*}
and 
\begin{equation*}
  \braket{{\bf r}|\hat V|\varphi}=\int \sum_{lm}Y_{lm}(\theta,\phi) V_l(\rho){\delta(\rho-\rho')\over\rho^2} Y_{lm}^*(\theta',\phi') \varphi({\bf r'})\d^3r'=
\end{equation*}
\begin{equation*}
  = \sum_{lm}Y_{lm}(\theta,\phi) V_l(\rho) \int Y_{lm}^*(\theta',\phi') \varphi(\rho{\bf\hat r'})\d\Omega'
\end{equation*}
or in Dirac notation 
\begin{equation*}
  \braket{{\bf r}|\hat V|\varphi}= \sum_{lm} \braket{{\bf\hat r}|lm}V_l(\rho) \bra{lm}\braket{\rho|\varphi}
\end{equation*}
and we recover (\ref{semi}).

So, to sum it up: semilocal pseudopotential is a general hermitian operator in the spherically symmetric problem (i.e. $\hat V=R^{-1}\hat VR$) and radially local. All such operators can be written in the form (\ref{semi}).

Now, it can be shown that if we make the assumption of radial locality, we get "correct" wavefunctions and energies in the linear approximation. We generally only take a few terms in the expansion (\ref{semi}), usually only $V_0$, $V_1$ and $V_2$, sometimes also $V_3$ and $V_4$.

\subsection{Separable Potentials}

The pseudopotential above (Hamman, Schlüter, Chiang) has the form 
\begin{equation*}
  \hat V=\sum_{lm} \ket{lm}V_l(\rho)\bra{lm} =V_{loc}(\rho)+\sum_{lm} \ket{lm}[V_l(\rho)-V_{loc}(\rho)]\bra{lm}
\end{equation*}
Or, equivalently, in the $\bf r$ representation: 
\begin{equation*}
  V({\bf r},{\bf r'})=\braket{{\bf r}|\hat V|{\bf r'}}= V_{loc}(\rho)\delta({\bf r}-{\bf r'})+{\delta(\rho-\rho')\over\rho^2} \sum_{lm}Y_{lm}({\bf\hat r})[V_l(\rho)-V_{loc}(\rho)]Y_{lm}^*({\bf\hat r'})
\end{equation*}
The first term doesn't cause a problem. Let's denote the second term (which is semilocal) simply by $v$: 
\begin{equation*}
  v=\sum_{lm} \ket{lm}[V_l(\rho)-V_{loc}(\rho)]\bra{lm}
\end{equation*}
Let's choose a complete but otherwise arbitrary set of functions $\ket{\phi_i}$ (they contain both a radial and an angular dependence) and define a matrix $U$ is by the equation 
\begin{equation*}
  \sum_j U_{ij}\braket{\phi_j|v|\phi_k}=\delta_{ik}
\end{equation*}
then ($\ket{\psi}=\ket{\phi_k}\alpha_k$): 
\begin{equation*}
  v\ket{\psi} =\sum_{ik}v\ket{\phi_i}\delta_{ik}\alpha_k =\sum_{ijk}v\ket{\phi_i}U_{ij}\braket{\phi_j|v|\phi_k}\alpha_k =\sum_{ij}v\ket{\phi_i}U_{ij}\braket{\phi_j|v|\psi}
\end{equation*}
So any Hermitian operator (including $v$) can be transformed exactly into the following form 
\begin{equation*}
  v=\sum_{ij}v\ket{\phi_i}U_{ij}\bra{\phi_j}v
\end{equation*}
We diagonalize the matrix $U$ by choosing such functions $\ket{\bar\phi_i}$ for which the matrix $\braket{\bar\phi_j|v|\bar\phi_k}$ (and hence the corresponding matrix $U$) is equal to \one. We can find such functions for example using the Gram-Schmidt orthogonalization procedure on $\ket{\phi_i}$ with a norm $\braket{f|v|g}$ (for functions $f$ and $g$), more on that later. Then 
\begin{equation}
  v =\sum_{i}v\ket{\bar\phi_i}{1\over\braket{\bar\phi_i|v|\bar\phi_i}} \bra{\bar\phi_i}v =\sum_{i}v\ket{\bar\phi_i}\bra{\bar\phi_i}v  \label{vsep}
\end{equation}
We could take any $\ket{\phi_i}$ and orthogonalize them. But because we have $v$ in the form of (\ref{semi}), we will be using $\ket{\phi_i}$ in the form $\ket{\phi_i}=\ket{R_{nl}}\ket{lm}$, because it turns out we will only need to orthogonalize the radial parts. The first term in (\ref{vsep}) then corresponds to the KB potential. We of course take more terms and get accurate results without ghost states.

Let's look at the orthogonalization. We start with the wavefunctions: 
\begin{equation*}
  \ket{\phi_i}=\ket{R_{nl}}\ket{lm}
\end{equation*}
where $R_{nl}(\rho)=\braket{\rho|R_{nl}}$ and $i$ goes over all possible triplets $(nlm)$.

We can also relate the $i$ and $n$, $l$, $m$ using this formula
\begin{equation*}
  i_{nlm}=\sum_{k=1}^{n-1}k^2+\left(\sum_{k=0}^{l-1} (2k+1)\right) + (l+m+1)= {(n-1)n(2n-1)\over6} + l(l+1)+m+1
\end{equation*}

The operator $v$ acts on these $\ket{\phi_i}$ like this 
\begin{equation*}
  \braket{{\bf r}|v|\phi_i} =\braket{{\bf r}|v|R_{nl}}\ket{lm} =\bra{{\bf\hat r}}\braket{\rho|V_l(\rho)|R_{nl}}\ket{lm} =V_l(\rho)R_{nl}(\rho)Y_{lm}({\bf\hat r})
\end{equation*}
Now we need to construct new orthogonal set of functions $\ket{\bar\phi_i}$ satisfying 
\begin{equation*}
  \braket{\bar\phi_i|v|\bar\phi_j}=\delta_{ij}
\end{equation*}
This can be done using several methods, we chose the Gram-Schmidt orthogonalization procedure, which works according to the following scheme: 
\begin{eqnarray*}
\ket{\tilde\phi_1}&=&\one{1\over\sqrt{\braket{\phi_1|v|\phi_1}}}\ket{\phi_1} ;\quad\quad \quad\quad\quad\quad\quad \quad\quad\quad\quad\quad \ket{\bar\phi_1}={1\over\sqrt{\braket{\tilde\phi_1|v|\tilde\phi_1}}} \ket{\tilde\phi_1} \\
\ket{\tilde\phi_2}&=& \left(\one -\ket{\bar\phi_1}\bra{\bar\phi_1}v \right){1\over\sqrt{\braket{\phi_2|v|\phi_2}}}\ket{\phi_2};\quad\quad \quad\quad\quad\quad\quad \ket{\bar\phi_2}={1\over\sqrt{\braket{\tilde\phi_2|v|\tilde\phi_2}}} \ket{\tilde\phi_2} \\
\ket{\tilde\phi_3}&=& \left(\one -\ket{\bar\phi_1}\bra{\bar\phi_1}v -\ket{\bar\phi_2}\bra{\bar\phi_2}v \right){1\over\sqrt{\braket{\phi_3|v|\phi_3}}}\ket{\phi_3};\quad\quad \ket{\bar\phi_3}={1\over\sqrt{\braket{\tilde\phi_3|v|\tilde\phi_3}}} \ket{\tilde\phi_3} \\
\dots& \\
\end{eqnarray*}
 We can verify by a direct calculation that this procedure ensures 
\begin{equation*}
  \braket{\bar\phi_i|v|\bar\phi_j}=\delta_{ij}
\end{equation*}
It may be useful to compute the normalization factors explicitly: 
\begin{eqnarray*}
\braket{\tilde\phi_1|v|\tilde\phi_1}&=&1 \\
\braket{\tilde\phi_2|v|\tilde\phi_2}&=&1 -{\braket{\phi_2|v|\bar\phi_1}\braket{\bar\phi_1|v|\phi_2} \over\braket{\phi_2|v|\phi_2}} \\
\braket{\tilde\phi_3|v|\tilde\phi_3}&=&1 -{\braket{\phi_3|v|\bar\phi_1}\braket{\bar\phi_1|v|\phi_3}+ \braket{\phi_3|v|\bar\phi_2}\braket{\bar\phi_2|v|\phi_3} \over\braket{\phi_3|v|\phi_3}} \\
...& \\
\end{eqnarray*}
 we can also write down a first few orthogonal vectors explicitly: 
\begin{eqnarray*}
\ket{\bar\phi_1}&=&{\ket{\phi_1}\over\sqrt{\braket{\phi_1|v|\phi_1}}} \\
\ket{\bar\phi_2}&=&{\ket{\phi_2}\braket{\phi_1|v|\phi_1}-\ket{\phi_1}\braket{\phi_1|v|\phi_2} \over\sqrt{(\braket{\phi_1|v|\phi_1}\braket{\phi_2|v|\phi_2}-\braket{\phi_2|v|\phi_1}\braket{\phi_1|v|\phi_2})\braket{\phi_1|v|\phi_1}\braket{\phi_2|v|\phi_2}}} \\
\end{eqnarray*}
 Now the crucial observation is 
\begin{equation*}
  \bra{lm}\braket{R_{nl}|v|R_{n'l'}}\ket{l'm'}= \braket{R_{nl}|V_l(\rho)|R_{n'l}}\delta_{ll'}\delta_{mm'}
\end{equation*}
which means that $\braket{\phi_i|v|\phi_j}=0$ if $\ket{\phi_i}$ and $\ket{\phi_j}$ have different $l$ or $m$. In other words $\ket{\phi_i}$ and $\ket{\phi_j}$ for different $\ket{lm}$ are already orthogonal. Thus the G-S orthogonalization procedure only makes the $R_{nl}$ orthogonal for the same $\ket{lm}$. To get explicit expressions for $\ket{\bar\phi_i}$, we simply use the formulas above and get: 
\begin{equation*}
  \ket{\phi_i}=\ket{R_{nl}}\ket{lm}\quad\to\quad \ket{\bar\phi_i}=\ket{\bar R_{nl}}\ket{lm}
\end{equation*}
where we have constructed new $\ket{\bar R_{nl}}$ from original $\ket{R_{nl}}$: 
\begin{eqnarray*}
\ket{\bar R_{10}}&=&{\ket{R_{10}}\over\sqrt{\braket{R_{10}|V_0|R_{10}}}} \\
\ket{\bar R_{20}}&=&{\ket{R_{20}} -\ket{\bar R_{10}}\braket{\bar R_{10}|V_0|R_{20}}\over\sqrt{\dots}} \\
\ket{\bar R_{21}}&=&{\ket{R_{21}}\over\sqrt{\braket{R_{21}|V_1|R_{21}}}} \\
\ket{\bar R_{30}}&=&{\ket{R_{30}} -\ket{\bar R_{10}}\braket{\bar R_{10}|V_0|R_{30}} -\ket{\bar R_{20}}\braket{\bar R_{20}|V_0|R_{30}} \over\sqrt{\dots}} \\
\ket{\bar R_{31}}&=&{\ket{R_{31}} -\ket{\bar R_{21}}\braket{\bar R_{21}|V_1|R_{31}} \over\sqrt{\dots}} \\
\ket{\bar R_{32}}&=&{\ket{R_{32}}\over\sqrt{\braket{R_{32}|V_1|R_{32}}}} \\
\ket{\bar R_{40}}&=&{\ket{R_{40}} -\ket{\bar R_{10}}\braket{\bar R_{10}|V_0|R_{40}} -\ket{\bar R_{20}}\braket{\bar R_{20}|V_0|R_{40}} -\ket{\bar R_{30}}\braket{\bar R_{30}|V_0|R_{40}} \over\sqrt{\dots}} \\
\ket{\bar R_{41}}&=&{\ket{R_{41}} -\ket{\bar R_{21}}\braket{\bar R_{21}|V_1|R_{41}} -\ket{\bar R_{31}}\braket{\bar R_{31}|V_1|R_{41}} \over\sqrt{\dots}} \\
&\dots& \\
\end{eqnarray*}
 Ok, so we have constructed new $\ket{\bar R_{nl}}$ from $\ket{R_{nl}}$ which obey 
\begin{equation}
  \braket{\bar R_{nl}|V_l|\bar R_{n'l}}=\delta_{nn'}  \label{orthog}
\end{equation}
so for every $V_l$, we construct $\ket{\bar R_{nl}}$ for $n=l+1,\,\, l+2, \cdots$. Let's continue: 
\begin{equation*}
  v\ket{\bar\phi_i}=V_l(\rho)\ket{\bar R_{nl}}\ket{lm}
\end{equation*}
and finally we arrive at the separable form of the $l$ dependent pseudopotential 
\begin{equation}
  v =\sum_{i}v\ket{\bar\phi_i}\bra{\bar\phi_i}v =\sum_{i}V_l(\rho)\ket{\bar R_{nl}}\ket{lm} \bra{lm}\bra{\bar R_{nl}}V_l(\rho)  \label{Vsep}
\end{equation}
Note: the $V_l$ is actually $V_l-V_{loc}$, but this is just a detail.

To have some explicit formula, let's write how the separable potential acts on a wavefunction: 
\begin{equation*}
  (v\psi)({\bf r})=\braket{{\bf r}|v|\psi}= \sum_i\braket{{\bf\hat r}|lm}\braket{\rho|V_l(\rho)|\bar R_{nl}} \bra{\bar R_{nl}}V_l(\rho)\braket{lm|\psi}=
\end{equation*}
\begin{equation*}
  =\sum_iY_{lm}({\bf\hat r})\bar R_{nl}(\rho)V_l(\rho) \int \bar R_{nl}(\rho')V_l(\rho')\int Y_{lm}^*({\bf\hat r'})\psi({\bf r'})\,\d \Omega'\,\rho'^2 \d\rho'=
\end{equation*}
\begin{equation*}
  =\sum_iY_{lm}({\bf\hat r})\bar R_{nl}(\rho)V_l(\rho) \int \bar R_{nl}(\rho')V_l(\rho') Y_{lm}^*({\bf\hat r'})\psi({\bf r'})\,\d^3r'
\end{equation*}

To have some insight on what we are actually doing: we are making the local potential $V_l$ nonlocal using: 
\begin{equation}
  V_l=\sum_{n=l+1}^\infty V_l\ket{\bar R_{nl}}\bra{\bar R_{nl}}V_l  \label{Vlsep}
\end{equation}
where 
\begin{equation*}
  \braket{\bar R_{nl}|V_l|\bar R_{n'l}}=\delta_{nn'}
\end{equation*}
or in ${\bf r}$ representation: 
\begin{equation*}
  V_l(\rho)\psi(\rho {\bf\hat r})=\sum_n V_l(\rho)\bar R_{nl}(\rho) \int\bar R_{nl}(\rho')V_l(\rho')\psi(\rho'{\bf\hat r})\rho'^2\d \rho'
\end{equation*}
which is useful when computing integrals of this type 
\begin{equation*}
  V_{ij} =\int\phi_i(\rho) V_l \phi_j(\rho) \rho^2\d^3 \rho =\braket{i|V_l|j}= \sum_n \braket{i|V_l|{\bar R_{nl}}}\braket{\bar R_{nl}|V_l|j}
\end{equation*}
\begin{equation*}
  \braket{i|V_l|{\bar R_{nl}}}=\int\phi_i(\rho)V_l(\rho)\bar R_{nl}(\rho) \rho^2\d\rho
\end{equation*}
because the integral on the left hand side actually represents $N^2$ integrals, where $N$ is the number of basis vectors $\ket{\phi_i}$. The sum on the right hand side however only represents $K\cdot N$ integrals, where $K$ is the number of terms taken into account in (\ref{Vlsep}). Of course taking only finite number of terms in (\ref{Vlsep}) is only an approximation to $\hat V_l$. In our case, we don't need these 1D integrals (which can be easily computed directly, because $V_l$ is local and the basis functions $\phi_i$ are nonzero only around a node in the mesh, which means that the matrix $V_{ij}$ is sparse), but 3D integrals, where angular parts of $V$ are nonlocal and radial part is local (so the matrix $V_{ij}$ is dense), so the above procedure is the only way how to proceed, because we decompose the matrix $V_{ij}$ into the sum of matrices in the form $p_ip_j^*$, which can easily be handled and solved.

The scheme for the separation described above works for any functions $R_{nl}(\rho)$. Because of the form of the expansion (\ref{Vlsep}) however, we will use $R_{nl}$ from one atomic calculation. We need to approximate $V_l$ by as few terms as possible, so imagine how the $V_l(\rho)$ acts on the lowest radial function in the $l$ subspace, which is $\ket{R_{l+1;l}}$ and we see that all the terms in (\ref{Vlsep}) except the first one $V_l\ket{\bar R_{l+1;l}}\bra{\bar R_{l+1;l}}V_l$ give zero, because they are orthogonal to $\ket{R_{l+1;l}}$. For the function $\ket{R_{l+2;l}}$ all the terms except the first two are zero, because $\braket{\bar R_{nl}|V_0|R_{l+2;l}}\neq0$ only for $n=l+1$ or $n=l+2$ (because the vectors $\ket{R_{l+1;l}}$ and $\ket{R_{l+2;l}}$ span the same subspace as $\ket{\bar R_{l+1;l}}$ and $\ket{\bar R_{l+2;l}}$ and using (\ref{orthog})) For functions, which are a little different from all $\ket{R_{nl}}$ ($n>l$), we won't genereally get precise results taking any (finite) number of terms in (\ref{Vlsep}), but the higher terms should give smaller and smaller corrections.

So, to sum it up: We take all the $V_l$ in (\ref{Vsep}) as we did in (\ref{semi}). Theoretically we should take $\bar R_{nl}$ for all $n=l+1,\,\, l+2,\,\,l+3,\dots$, but practically it suffices to only take several $\bar R_{nl}$ for a given $l$ from one atomic calculaction.

Let's give an example: we are calculating 14 electrons, so we will only take into account the lowest 14 eigenvalues in the Kohn sham equations, which are $\ket{\phi_1}$ up to $\ket{\phi_{14}}$. The lowest radial functions in each $l$ subspace are $\ket{\phi_i}$ for $i=1,3,4,5,10,11,12,13,14$ and on these 9 functions we get a precise result with only one term in the expansion (\ref{Vlsep}). For the other 5 functions ($i=2,6,7,8,9$) we will have to take into account more terms. Let's look in more detail at the case $l=0$ (i.e. $i=1,2,6$). Then 
\begin{equation*}
  V_0= V_0\ket{\bar R_{10}}\bra{\bar R_{10}}V_0+ V_0\ket{\bar R_{20}}\bra{\bar R_{20}}V_0+ V_0\ket{\bar R_{30}}\bra{\bar R_{30}}V_0+ \dots
\end{equation*}
and for the case $i=1$ we see that one term in (\ref{Vlsep}) is enough: 
\begin{equation*}
  v\ket{\phi_1}=v\ket{R_{10}}\ket{00}=V_0\ket{R_{10}}\ket{00}= V_0\ket{\bar R_{10}}\bra{\bar R_{10}}V_0\ket{R_{10}}\ket{00}
\end{equation*}
because $\braket{\bar R_{n0}|V_0|R_{10}}=0$ for $n>1$. For the case $i=2$ we get the correct result with 2 terms in (\ref{Vlsep})
\begin{equation*}
  v\ket{\phi_2}=v\ket{R_{20}}\ket{00}=V_0\ket{R_{20}}\ket{00}=( V_0\ket{\bar R_{10}}\bra{\bar R_{10}}V_0\ket{R_{20}}+ V_0\ket{\bar R_{20}}\bra{\bar R_{20}}V_0\ket{R_{20}} )\ket{00}
\end{equation*}
because $\braket{\bar R_{n0}|V_0|R_{20}}=0$ for $n>2$. For the case $i=6$ we need to take into account 3 terms etc. We can see from this example, that taking $\ket{R_{nl}}$ from one atomic calculation, we get precise results (with the same atom) only taking into account a finite number of terms in (\ref{Vlsep}), for 14 electrons actually only 3 terms. For several atoms calculation, we won't get precise results, but it should be a sufficiently good approximation.

The described method is general, the only drawback is that if we don't take functions $\ket{R_{nl}}$ which are similar to the solution, we need to take a lot of terms in (\ref{Vlsep}), resulting in many matrices of the form $p_ip_j^*$, which we don't want, even though, theoretically we can get a solution with any precision we want taking more and more terms in (\ref{Vlsep}).

See also \cite{blochl}.

\section{FEM}

\subsection{Introduction}

This chapter explains FEM and gives concrete formulas which are needed in the calculation.

\subsection{Pseudopotentials Formulation}

There are no problems with other matrix elements in (\ref{fem}) except 
\begin{equation*}
  V_{ij} =\int\phi_i({\bf r}) V \phi_j({\bf r}) \d^3 r =\int\braket{i|{\bf r}} \braket{{\bf r}|\hat V|j} \d^3 r =\braket{i|\hat V|j}
\end{equation*}
where 
\begin{equation*}
  \hat V=V_{loc}(\rho)+\sum_{nlm}V_l(\rho)\ket{\bar R_{nl}}\ket{lm} \bra{lm}\bra{\bar R_{nl}}V_l(\rho)
\end{equation*}
so 
\begin{equation*}
  V_{ij}=\braket{i|V_{loc}(\rho)|j}+ \bra{i}\sum_{nlm}V_l(\rho)\ket{\bar R_{nl}}\ket{lm} \bra{lm}\bra{\bar R_{nl}}V_l(\rho) \ket{j} =V_{ij}^{loc}+\sum_{nlm}p_ip_j^*
\end{equation*}
where the complex vector $p_i$ is given by 
\begin{equation*}
  p_i^{(nlm)}=\braket{i|lm}V_l(\rho)\ket{\bar R_{nl}}= \int\braket{i|{\bf r}}\braket{{\bf\hat r}|lm} \braket{\rho|V_l(\rho)|\bar R_{nl}}\d^3 r= \int \phi_i({\bf r})Y_{lm}({\bf\hat r})V_l(\rho)\bar R_{nl}(\rho)\d^3 r
\end{equation*}
and 
\begin{equation*}
  V_{ij}^{loc}=\int\phi_i({\bf r}) V_{loc}(\rho) \phi_j({\bf r}) \d^3 r
\end{equation*}
and $Y_{lm}({\bf\hat r})$, $\bar R_{nl}(\rho)$ and $V_l(\rho)$ are given functions. Noticing that 
\begin{equation*}
  \sum_m p_ip_j^*= \int \phi_i({\bf r})Y_{lm}({\bf\hat r})V_l(\rho)\bar R_{nl}(\rho)\d^3 r \int \phi_j({\bf r'})Y_{lm}^*({\bf\hat r'})V_l(\rho')\bar R_{nl}(\rho')\d^3 r'=
\end{equation*}
\begin{equation*}
  =\int\int Y_{lm}({\bf\hat r})Y_{lm}^*({\bf\hat r'})V_l(\rho)\bar R_{nl}(\rho) \phi_i({\bf r}) \phi_j({\bf r'})V_l(\rho')\bar R_{nl}(\rho')\d^3 r\d^3 r'=
\end{equation*}
and using (\ref{lsum}) we get 
\begin{equation*}
  \sum_m p_ip_j^*= \int\int {4\pi\over 2l+1}P_l({\bf\hat r}\cdot{\bf\hat r'})V_l(\rho)\bar R_{nl}(\rho) \phi_i({\bf r}) \phi_j({\bf r'})V_l(\rho')\bar R_{nl}(\rho')\d^3 r\d^3 r'
\end{equation*}
which is a real number, thus $\sum_{nlm}p_ip_j^*$ is also a real number, which means that we can calculate with only the real parts of the matrix $p_ip_j^*$, because the imaginary parts cancels out in the result: 
\begin{equation*}
  \sum_{nlm}p_ip_j^*=\Re\left(\sum_{nlm}p_ip_j^*\right)= \sum_{nlm}\Re(p_ip_j^*)
\end{equation*}
let $p_i=a_i+ib_i$ then 
\begin{equation*}
  \Re(p_ip_j^*)=\Re((a_i+ib_i)(a_j-ib_j))=a_ia_j+b_ib_j
\end{equation*}
and 
\begin{equation*}
  V_{ij}=V_{ij}^{loc}+\sum_{nlm}(a_ia_j+b_ib_j)
\end{equation*}
where 
\begin{equation*}
  a_i= \sqrt{{2l+1\over4\pi}{(l-m)!\over(l+m)!}} \int \phi_i({\bf r})P_l^m(\cos\theta)\cos(m\phi)V_l(\rho)\bar R_{nl}(\rho)\d^3 r
\end{equation*}
\begin{equation*}
  b_i= \sqrt{{2l+1\over4\pi}{(l-m)!\over(l+m)!}} \int \phi_i({\bf r})P_l^m(\cos\theta)\sin(m\phi)V_l(\rho)\bar R_{nl}(\rho)\d^3 r
\end{equation*}
just don't confuse the basis function $\phi_i({\bf r})$ with the spherical integration variable $\phi$.

\subsection{Example on Si}

There are only two valence electrons to take into account, thus we have only 2 $n$ in the summation $(nlm)$. The potentials in the Schrödinger equation are 
\begin{equation*}
  V=V_{local}+V_{nonlocal}
\end{equation*}
\begin{equation*}
  V_{local}=V_H+V_{XC}+V_{loc}
\end{equation*}
\begin{equation*}
  \hat V_{nonlocal}= \sum_{nlm}V_l(\rho)\ket{\bar R_{nl}}\ket{lm} \bra{lm}\bra{\bar R_{nl}}V_l(\rho)
\end{equation*}
There are just $V_0$, $V_1$ and $V_2$.

We probably need to calculate $\bar R_{10}$, $\bar R_{20}$, $\bar R_{21}$, $\bar R_{30}$, $\bar R_{31}$, $\bar R_{32}$, but I am not completely sure. We get maybe around 18 complex matrices, which means 36 real matrices of the form $a_ia_j$. The input for the solver is 36 real vectors $a$, $b$, $c$, $d$, $e$,\dots and sparse matrices $V^{loc}$, $M$, and $K$. The solver needs to solve 
\begin{equation*}
  (K+V^{loc}+a^Ta+b^Tb+c^Tc+d^Td+e^Te+\cdots)q=EMq
\end{equation*}

\section{Finite Element Method}
